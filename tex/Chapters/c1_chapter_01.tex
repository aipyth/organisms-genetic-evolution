%!TEX root = ../thesis.tex

\chapter{Еволюційні Алгоритми}
\label{chap:review}  %% відмічайте кожен розділ певною міткою -- на неї наприкінці необхідно посилатись


Традиційні детерміновані методи градієнтної оптимізації, такі як 
градієнтний спуск, покладаються на обчислення градієнтів цільової функції.
Вони використовують ці дані для ітеративного 
коригування змінних в алгоритмі в напрямку зменшення або збільшення значення функції.
Таким чином за допомогою таких методів ми знаходимо локальний або глобальний мінімум.

Однак градієнтні методи мають певні недоліки.
Не завжди у реальних задачах, які включають оптимізацію, ми можемо мати достатньо
інформації про процеси, щоб отримати цільову функцію, над якою проводимо оптимізацію.
Як приклад, одну з таких функцій можна інтуітивно описати як <<чорний ящик>>, 
що означає, що вона є прихованою для нас, видає лише результат на 
основі вхідних даних та нічого більше.
Також існують мультимодальні задачі, де градієнтні методи мають тенденцію 
збігатися до локальних мінімумів.
Крім того, вони не підтримують багатоцільову оптимізацію за замовчуванням 
і можуть не справлятися з проблемами високої розмірності.

У тей же час маємо \textbf{еволюційні алгоритми}, які використовують 
стохастичний підхід, працюють з популяцією рішень і не потребують
градієнтних обчислень.
Основними їхніми перевагами є властивість досліджувати великий простір рішень,
знаходити потенційні глобальні оптимуми в складних, мультимодальних задачах.
Це пов'язано з тим, що їм притаманне різноманіття популяцій
та варіаційні оператори.
У їх основі лежать механізми, натхнені біологічною еволюцією, такі як відбір,
мутація, рекомбінація.
Це підвищує їхню адаптивність і гнучкість, дозволяючи їм працювати з цільовими 
функціями, які є недиференційованими, розривними або навіть невідомими.
Також такі методи вміють обробляти багатоцільові задачі,
підтримуючи різноманітний набір рішень представляючи
різні компроміси між цілями.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Визначення та принципи роботи еволюційних алгоритмів}

Витоки еволюційних алгоритмів простежуються до основних принципів 
біологічної еволюції. 
Процес еволюції організмів завжди був цікавою цікавою темою для науковців.
Як біологів цікавили закони еволюції, її принципи так науковців у сфері 
комп'ютерних наук цікавив механізм розвитку організмів, їх змога пристосовуватися
та навчатися.
Комп'ютерні вчені прагнули імітувати природний спосіб 
адаптації до мінливого середовища та еволюції видів протягом 
мільйонів років, щоб створити надійні та адаптивні алгоритми для 
розв'язування складних задач. Це призвело до розробки еволюційних алгоритмів,
які є набором обчислювальних моделей, що імітують процес природного відбору 
та генетичної мінливості.

\begin{definition}
Еволюційний алгоритм (ЕА) --- це алгоритм, що належить до колекції технік 
еволюційних обчислень, які є натхненні біологічною еволюцією.
\end{definition}

Більшість EA можна розділити на генераційні алгоритми, які оновлюють 
всю вибірку один раз за ітерацію, і стаціонарні алгоритми, які 
оновлюють вибірку декількома рішеннями-кандидатами за один раз. 
До найпоширеніших алгоритмів належать генетичний алгоритм (GA) 
та еволюційні стратегії (ES), причому для кожного з них існують 
як генеративні, так і стаціонарні версії \cite{luke_essentials_2013}.

Об'єктом цих алгоритмів є популяції індивідів, яких ми інтерпретуємо 
як потенційні рішення задачі. 
У еволюційних алгоритмах використовуються різні принципи, такі як:
\begin{enumerate}
  \item спадковість
  \item природний відбір
\end{enumerate}

Впродовж часу організми у популяції еволюціонують за правилами цих принципів, які
диктують механізми:
\begin{itemize}
  \item розмноження
  \item мутації
  \item рекомбінації
  \item відбору
\end{itemize}

Та не завжди у алгоритмах можуть використовувати усі види таких механізмів.
Початковим степенем є еволюційні стратегії (Evolution Strategies), які є сімейством
алгоритмів. Вони мають просту процедуру, що складається з вибору
усіканням (Truncation selection) та зазвичай одним
з механізмів зміни --- мутації \cite{luke_essentials_2013}.

Однією з найпростіших є
$\left( \mu, \lambda \right)$ стратегія еволюції. Параметри $\mu$ та 
$\lambda$ у назві індикують розміри вибірок у алгоритмі: $\mu$ означає кількість
осіб у відборі, а $\lambda$ --- кількість отриманих нащадків.
Також зазвичай початкова популяція має саме $\lambda$ осіб.
У підборі параметрів до алгоритму існує важливе правило --- $\lambda$ 
повинне бути кратним $\mu$. Наприклад, позначають
алгоритм при підібраних параметрах як "$(10, 20)$ Еволюційна Стратегія".

\begin{lstlisting}[caption={$(\mu,\lambda)$ Еволюційна Стратегія}]
mu := number of selected parents
lambda := number of generate offsprings
P := GenerateInitialPopulation(lambda)
best := null
while best is null or best is ideal solution or we run out of time:
  best := individual for which fitness(individual) > fitness(best)
  S := TruncationSelection(P, mu)
  P := {}
  for each s in S:
    do lambda/mu times:
      P := Union(P, Mutation(Copy(s)))
endwhile
return best
\end{lstlisting}


У стратегії $\left( \mu + \lambda \right)$ символ "+" позначає
інший метод відбору особин для наступного покоління у порівнянні із
$\left( \mu, \lambda \right) $.
Цей метод вносить елемент елітизму в еволюційний процес.
Після процесу відбору популяція не зануляється, а замінюється на
результат відбору.
Потім відбувається процес мутації як у звичайній
$\left( \mu, \lambda \right)$ стратегії.
Це дозволяє батькам жити в наступному поколінні, 
якщо вони краще пристосовані, ніж їхні діти.


\subsection{Популяції}
Поняття популяції є ключовим в еволюційних алгоритмах.
Популяція у еволюційних алгоримах це набір потенційних рішень.

При побудові алгоритму так чи інакше можна стикнутися із питанням творення початкової
популяції.
При початковій популяції важливо досягти різноманітності у рішеннях,
що дозволить дослідити різні частини простору розв'язків, яка
призведе до підвищення йморвірності знаходження глобального оптимуму.
Часто достатньо створювати початкову популяцію випадковим чином 
за допомогою рівномірного розподілу. Така створена популяція може охопити 
велику область простору розв'язків, досягаючи варіативності у рішеннях на початку.

За відомою інформацією про простір, такою як можливі підпростори оптимальних рішень,
можна створити початкову популяцію для швидшої збіжності алгоритму. Таку інформацію
можна отримати з попереднього досліду простору,
коригуючи параметри на дослідження всього простору.

Важливо згадати про два підходи до еволюції популяцій.
\begin{enumerate}
  \item \textbf{Генеративний}. Наступна популяція цілком замінюється новою.
  \item \textbf{Стаціонарний}. Зберігається поточна популяція
    в умовах її ітеративного розмноження (індивіди змінюються).
    Дозволяє потенційно хорошим рішенням залишатися у популяції надовше.
\end{enumerate}

Стаціонарний підхід має дві особливості:
\begin{enumerate}
  \item Він використовує вдвічі менше пам'яті, ніж традиційний генеративний алгоритм, оскільки одночасно існує лише одна популяція.
  \item По-друге, він є досить експлуататорським (тобто перевикористовує наявні
    рішення для отримання нових, що дає відтінок локального пошуку)
    порівняно з генеративним підходом: батьки залишаються в популяції,
    можливо, дуже довго, а отже, подібно до $(\mu + \lambda)$ еволюційної 
    стратегії та елітизму,
    існує ризик того, що система \textit{передчасно} зведеться до копій
    кількох дуже пристосованих особин \cite{luke_essentials_2013}.
\end{enumerate}

Ще однією ключовою особливістю еволюційних алгоритмів є розмір популяції. 
Вона повинна бути достатньо великою, щоб підтримувати різноманітність 
і дозволяти широке дослідження простору розв'язків, але не настільки 
великою, щоб стати обчислювально непосильною. 
Не існує універсального розміру популяції, оскільки він 
визначається складністю завдання, доступними комп'ютерними 
ресурсами та конкретним еволюційним алгоритмом, що використовується.



\subsection{Фітнес-функція}

У процесі бере участь основна функція, яка скеровує популяції до кращих рішень.
\begin{definition}
  Фітнес-функція --- це функція, яка оцінює якість або доречність кожного рішення,
  що дозволяє скеровувати процес до все кращих рішень.
\end{definition}

Чим вищий показник пристосованості індивіда, тим краще він
пристосований до вирішення проблеми. 
Ця оцінка впливає на те, чи пройде індивід відбір
в майбутньому поколінні. 
Як наслідок, хороша фітнес-функція повинна бути здатна 
відрізняти відмінні рішення від жахливих і забезпечувати 
чіткий шлях до розвитку.

Побудова фітнес-функції часто є складним завданням, 
яке значною мірою залежить від конкретної задачі, що вирішується. 
Вона може бути простим з математичне рівняння, або складною, 
як система правил. 
Саме ця функція <<повідомляє>> алгоритму про суть процесу, над яким
проводиться робота.
Фітнес-функція повинна відображати обмеження та цілі проблеми.
Якщо вона розроблена неправильно, це може ввести в оману 
процес пошуку і призвести до хибних результатів.

Варто також підкреслити, що фітнес-функція повинна бути 
\textbf{максимально ефективною} з точки зору обчислень. 
Обчислювально дорога функція пристосованості може значно 
сповільнити роботу еволюційного алгоритму, оскільки її 
потрібно обчислювати для кожної особини в популяції в кожному поколінні.


\subsection{Відбір}

Механізм відбору слугує базовою ланкою процесу формування наступного покоління.
На основі різних алгоритмів відбору досягаються різні варіації набору
індивідів для рекомбінації, мутації та потрапляння у наступну популяцію.
За правилом, особи з вищим показником пристосованості з 
більшою ймовірністю будуть відібрані для розмноження. 
Це гарантує, що найбільш перспективні рішення передаються з 
покоління в покоління.
Але у певних алгоритмах відбору існує варіант потрапляння
слабких осіб у наступну популяцію для підтримання різноманітності.

Наведемо деякі найвідоміші процеси відбору:


\textbf{Пропорційний відбір} ґрунтується на припущенні, що 
ймовірність того, що індивід буде обраний, пропорційна 
його фітнес-функції. 
Якщо $f_i$ --- це фітнес-функція i-ої особи, 
а $N$ --- загальна кількість осіб у популяції, 
то ймовірність відбору $P(i)$ для i-ої особи обчислюється наступним чином.
\[
P(i) = \frac{f_i}{\sum_{j=1}^{N} f_j}
\].

\textbf{Відбір усіканням} (Truncation selection) є дуже простим методом відбору.
Для формування наступного покоління обираються лише найкращі $n$
осіб з найкращим рейтингом фітнес-функції.
Наприклад, якщо $n$ дорівнює 10, то буде обрано лише 10 найкращих
осіб у популяції.


\subsection{Мутація та рекомбінація}

Мутація та рекомбінація є двома ключовими механізмами в 
еволюційних алгоритмах, оскільки вони слугують фундаментальними 
джерелами різноманітності, що дозволяє досліджувати простір 
розв'язків, виходячи із локальних мінімумів.

Мутація проводить незначні випадкові зміни в особі.
Задають певну ймовірність події мутації.
Зазвичай таку ймовірність задають досить малою, в межах 0.01 та мешне.
Така рандомізація слугує для збереження різноманітності 
популяції та запобігає передчасній збіжності алгоритму до 
локального оптимуму. В тей же час, велика ймовірність мутації
може призвести до сильного розмаїття популяції, що зменшує
швидкість збіжності.

Як приклад мутації можна навести додавання шумів до одного
обраного індивіда. Генерується аргумент --- випадкове значення з
гаусового розподілу із заданими параметрами в залежності від задачі.
Далі цей аргумент додається до значення індивіда.
Змінюючи параметри розподілу, з якого беремо величину шуму, можна
керувати процесом знаходження розв'язків: чи будуть вони генеруватися
поблизу локальних оптимумів, чи ж зміни приведуть до дослідження нових
підпросторів розв'язків.


Рекомбінація (recombination) є ще одним механізмом утворення різноманітності у популяції.
Вона ще відома як кросинговер (crossingover).
Але її механізм потребує не одну особу, а декілька або більше.
Існують як рекомбінації, подія яких залежить від ймовірності,
так і ті, що відбуваються завжди по отриманню осіб по відбору.
Цей механізм об'єднує "батьківських" особин для
утворення одного, двох, або й більше нащадків.
На меті стоїть утворення кращого нащадка, зливаючи
"хороші" компоненти батьків.

Існує безліч варіантів поєднання двох рішень, для створення ліпшого.
Кожен з них показує себе краще у певних своїх задачах.
Для створення кращого алгоритму та параметрів під нього потрібно
експерментувати та досліджувати простір рішень у задачі.
Саме сукупнусть процесу відбору, рекомбінації та мутації
в залежності від обраних варіантів може давати різні результати.
Важливо знайти тей, що надає гарний баланс між дослідженням простору
та пошуком локальних рішень.


\subsection{Елітизм}

Елітизм це проста техніка.
Вона полягає у додаванні до наступної популяції
найкращих індивідів з попередньої. Вона походить від
стратегії $\left( \mu + \lambda \right)$, яка зберігає
у наступну популяцію індивідів, що пройшли відбір.
Все, що наслідує цю еволюційну стратегію має характер елітизму.

Елітизм схожий на відкладення найкращої роботи в безпечну зону,
поки надалі проводиться дослідження нового простору.
Крім того, елітизм має потенціал для стабілізації
еволюційного процесу.
Без нього найкращі рішення може бути втрачене,
якщо воно не призведе до появи конкурентоспроможних нащадків,
що призведе до зміни якості найкращого рішення з плином часу. 
\hide{
Елітизм сприяє безперервному розвитку в напрямку кращих рішень,
гарантуючи, що найкращі рішення будуть передані наступному поколінню.
}

До речі, статичний підхід є певном мірою елітизму, бо значна частина
осіб переходить у "наступну популяцію".




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Застосування}

Завдяки своїй адаптивності та гнучкості еволюційні алгоритми можна 
застосовувати до широкого спектру проблемних областей. Їх можна 
використовувати для оптимізації складних математичних функцій, 
наприклад, там, де традиційні методи оптимізації не спрацьовують. 
Вони використовуються в машинному навчанні для вибору функцій, 
налаштування гіперпараметрів і навіть для навчання нейронних мереж. 
Вони також знайшли застосування в таких сферах, як складання розкладу, 
планування маршрутів та ігри, де їх використовують для отримання 
високоякісних результатів за розумний проміжок часу. 
Кожна програма застосовує фундаментальні принципи еволюційних алгоритмів, 
адаптуючи їх до конкретних потреб і обмежень поставленої задачі.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Типи еволюційних алгоритмів}

Більшість еволюційних алгоритмів можна розділити на 
генераційні алгоритми, які оновлюють всю вибірку один раз за ітерацію,
і стаціонарні алгоритми, які оновлюють вибірку декількома рішеннями-кандидатами 
за один раз. 
До найпоширеніших алгоритмів належать генетичний алгоритм (GA) та 
еволюційні стратегії (ES), причому для кожного з них існують як генеративні,
так і стаціонарні версії \cite{luke_essentials_2013}.

Однак різноманітність алгоритмів на одним генетичних та еволюційних
стратегіях не закінчується. 
Хоча всі ці алгоритми мають спільні базові концепції, 
вони відрізняються конкретними процесами, 
які вони використовують для дослідження простору пошуку задачі. 
До еволюційних алгоритмів належать:
генетичні алгоритми (Genetic Algorithms),
стратегії еволюції (Evolution Strategies),
генетичне програмування (Genetic Programming),
диференціальна еволюція (Differential Evolution) 
та еволюційне програмування (Evolutionary Programming).


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Генетичні Алгоритми}

ГА натхненні природною еволюцією та генетикою і використовують 
популяцію індивідів (розв'язків), які еволюціонують у часі, 
для пошуку оптимальних або близьких до оптимальних розв'язків складних задач. 
Зображення розв'язків у вигляді двійкових рядків, 
які можна порівняти з хромосомами, є ключовою особливістю ГА. 
Кожен байт у рядку можна розглядати як ген, який представляє 
певну особливість розв'язку.

Хоча ГА зазвичай використовують двійкове кодування, 
вони не обмежуються цим форматом. 
Так, наприклад, у генетичному програмуванні використовують
коди програм як об'єкти у популяції та кодують ці програми
у дерева, або ж репрезентують як послідовності команд 
\cite{slowik_evolutionary_2020, luke_essentials_2013}.
Таким же чином, у ГА можна використовувати кодування з дійсними числами. 
Тепер кожен ген на хромосомі можна закодувати як число з плаваючою комою.
Це особливо корисно в задачах оптимізації зі змінними з дійсними числами. 
Він забезпечує більш пряме зображення простору розв'язків 
і може підвищити точність розв'язку. 
Фенотип буде зображатися більш прямо у генотип:
зменшиться спотворення простору фенотипів у простір генотипів.

Можна подумати, що через таке кодування рішень ГА стає
стратегією еволюції, які предтавляють рішення саме через
дійсні числа.
Але це не є так. Наведемо аргументи чому так.
\begin{enumerate}
\item Основна відмінність між ГА та ЕС полягає в тому, 
  як вони поводяться з генетичними операторами. 
  У той час як ГА часто використовують як кросинговер, 
  так і мутацію, причому кросинговер часто є домінуючим оператором, 
  ЕС, як правило, роблять більший акцент на мутації. 
\item ЕС часто використовують методи самоадаптації, 
  де сила мутації (кількість змін, спричинених мутацією) 
  також розробляється як частина рішення.
\item При зміні кодування кожного гена на число із плаваючою точкою
  не змінює поняття генотипу чи гена.
  Фактично репрезентація чисел через рядки аналогічна
  до реалізації арифметики у комп'ютерних системах.
  При зміні кодування змінюються також алгоритми
  рекомбінації, щоб підлаштуватися під конкретний тип
  вигляду генотипа.
\end{enumerate}

Генетичні алгоритми та еволюційні стратегії --- це дві різні 
точки в спектрі еволюційних алгоритмів, кожна з яких має 
свій власний набір якостей і переваг. 
Використання різних методів кодування, 
таких як кодування з плаваючою комою, 
і зміщення акценту на генетичні оператори підкреслюють 
універсальність і адаптивність цих методів. 
Вони пристосовуються до поставленого завдання, 
що робить їх важливими інструментами в оптимізації та машинному навчанні.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Критерії збіжності та завершення в еволюційних алгоритмах}

В еволюційних алгоритмах збіжність означає момент, 
коли алгоритм знайшов відповідне рішення або досяг точки, 
де подальші ітерації не дають помітного поліпшення відповіді. 
Це може вимірюватися шляхом відстеження якості найкращого 
рішення або середньої якості рішень популяції з плином часу. 
Коли ці показники більше не покращуються після кількох поколінь, 
вважатимемо, що алгоритм збігся.

На противагу цьому, критерії завершення - це умови,
які визначають, коли алгоритм має бути завершений. 
Максимальна кількість поколінь є типовою умовою завершення роботи.
Іншими критеріями можуть бути міра різноманітності 
розв'язків або обмеження на обчислювальні ресурси, 
наприклад, максимальний час роботи процесора.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Огляд попередніх робіт}

З моїх спостережень у області моделювання розвитку організмів у певному
середовищі я виділив би два джерела: 
статтю Натана Руя \cite{rooy_evolving_nodate} та DERL.

\subsection{Проста реалізація Натана Руя}

Натан Руй написав детальну статтю з еволюційних обчислень, зосередившись на
реалізації простої 2D-симуляції організмів.
На його ресурсі міститься детальний опис як організми еволюціонують і
пристосовуються до навколишнього середовища, використовуючи генетичний
алгоритм для оптимізації \cite{rooy_evolving_nodate}.

Основними в симуляції є два об'єкта: організм та їжа. 
Організм включає в себе нейронну мережу та функції для оновлення його курсу,
швидкості та положення. 
Коли організм ініціалізується вперше, його положення, курс, швидкість,
прискорення та ваги нейронної мережі генеруються випадковим чином.
Їжа --- це простий об'єкт, який містить координати x та у та уособлює певну 
енергетичну цінність. Ця енергетична цінність безпосередньо впливає на 
виживання організму в середовищі.

\subsection{Deep Evolutionary Reinforcement Learning}

Проект Deep Evolutionary Reinforcement Learning (DERL) досліджує взаємозв'язок 
між складністю навколишнього середовища, еволюцією морфології та здатністю до 
навчання інтелектуального управління. Дослідники пропонують обчислювальну платформу 
під назвою DERL, яка може розвивати різноманітні морфології агентів для 
навчання складним завданням переміщення та маніпулювання в складних середовищах. 
DERL імітує переплетені процеси дарвінівської еволюції протягом поколінь для пошуку 
морфологій і використовує навчання з підкріпленням протягом життя для вивчення 
інтелектуальної поведінки на основі низькорівневої егоцентричної сенсорної інформації.
DERL також використовує розподілений асинхронний еволюційний пошук для 
розпаралелювання обчислень, що лежать в основі навчання [2].

Дослідження підкреслює важливість еволюційних морфологій для полегшення 
навчання складних завдань. 
Однак створення штучних втілених агентів з добре адаптованими морфологіями в
різноманітних, складних середовищах є складним завданням через подвійні труднощі 
пошуку серед комбінаторно великої кількості можливих морфологій і 
обчислювального часу, необхідного для оцінки придатності через навчання впродовж життя.
Ці проблеми призвели до того, що попередні роботи були зосереджені на більш 
простих завданнях і обмежених морфологічних просторах.


% \section{(Назва першого підрозділу)}

% Перший розділ повинен бути присвячений огляду попередніх результатів за 
% тематикою вашого дослідження. У даному розділі повинні міститись вс' 
% визначення та описи, необхідні для подальшого викладення матеріалу, та результати 
% ваших попередників.

% Зауважимо, що наводити детальні доведення не ваших результатів необхідно 
% наводити лише тоді, коли вони містять якусь вкрай важливу інформацію для 
% саме ваших результатів.

% Також зауважимо, що абсолютно на всі не ваші результати повинні стояти 
% належним чином оформлені посилання.

% Розмір першого (оглядового) розділу не повинен перевищувати третини вашої 
% дипломної роботи (без урахування додатків).







% \begin{theorem}
% Використовуйте оточення \emph{theorem} для теорем.
% \end{theorem}
% \begin{proof}
% Для доведень використовуйте оточення \emph{proof}.
% \end{proof}
% \begin{theorem}
% Нумерація відбувається автоматично
% \end{theorem}
% \begin{claim}
% Використовуйте оточення \emph{claim} для тверджень.
% \end{claim}
% \begin{lemma}
% Використовуйте оточення \emph{lemma} для лем.
% \end{lemma}
% \begin{corollary}
% Використовуйте оточення \emph{corollary} для наслідків.
% \end{corollary}
% \begin{definition}
% Використовуйте оточення \emph{definition} для визначень.
% \end{definition}
% \begin{example}
% Використовуйте оточення \emph{example} для прикладів, на які є посилання.
% \end{example}
% \begin{remark}
% Використовуйте оточення \emph{remark} для зауважень. Зверніть увагу, як 
% веде себе команда \textbf{emph}
% \end{remark}


\chapconclude{\ref{chap:review}}

Наприкінці кожного розділу ви повинні навести коротенькі підсумки по його 
результатах. Зокрема, для оглядового розділу в якості висновків необхідно 
зазначити, які задачі у даній тематиці вже були розв'язані, а саме 
поставлена вами задача розв'язана не була (або розв'язана погано), тому у 
наступних розділах ви її й розв'язуєте.

Якщо ваш звіт складається з одного розділу, пропускайте висновок до 
нього~-- він повністю включається в загальні висновки до роботи
